-------------------------------
-- Para puntos de servicio de medida indirecta

spark-submit --class IndirectMeasureExtractorOptimized --master yarn --deploy-mode cluster --conf spark.kryoserializer.buffer.max=1024 --conf spark.sql.broadcastTimeout=-1 --conf spark.dynamicAllocation.initialExecutors=5 --conf spark.dynamicAllocation.minExecutors=5 --conf spark.dynamicAllocation.maxExecutors=300 --conf spark.driver.memory=20g --executor-memory 8GB --conf spark.memory.offHeap.enabled=true --conf spark.memory.offHeap.size=4g --conf spark.serializer=org.apache.spark.serializer.KryoSerializer --conf spark.memory.fraction=0.3 --jars $(echo ../../jars/*.jar | tr ' ' ',') --queue root.datanodo DAICE-spark-1.0-SNAPSHOT-jar-with-dependencies.jar 202312010000 202312310000 user/deptorecener/indirectMeasures/20231121 1000

------------------------------
-- Curvas de consumo

spark-submit --class OMDaiceExtractorV2 --master yarn --deploy-mode cluster --conf spark.kryoserializer.buffer.max=1024 --conf spark.sql.broadcastTimeout=-1 --conf spark.dynamicAllocation.initialExecutors=5 --conf spark.dynamicAllocation.minExecutors=5 --conf spark.dynamicAllocation.maxExecutors=300 --conf spark.driver.memory=20gb --executor-memory 5G --jars $(echo ../../jars/*.jar | tr ' ' ',') --queue root.datanodo DAICE-spark-1.0-SNAPSHOT-jar-with-dependencies.jar KAIFA 202311010000 202402010000


------------------------------
-- Para los puntos de servicio trifásicos

spark-submit --class IVDaiceExtractor --master yarn --deploy-mode cluster --conf spark.kryoserializer.buffer.max=1024 --conf spark.sql.broadcastTimeout=-1 --conf spark.dynamicAllocation.initialExecutors=5 --conf spark.dynamicAllocation.minExecutors=5 --conf spark.dynamicAllocation.maxExecutors=300 --conf spark.driver.memory=20gb --executor-memory 5GB --jars $(echo ../../jars/*.jar | tr ' ' ',') --queue root.datanodo DAICE-spark-1.0-SNAPSHOT-jar-with-dependencies.jar Grupo_fernanda 1704067200000 1706745600000 user/deptorecener/20240223

------------------------------
-- Para los puntos de servicio trifásicos 100k
spark-submit \
  --class IVDaiceExtractor \
  --master yarn \
  --deploy-mode cluster \
  --conf spark.kryoserializer.buffer.max=1024m \
  --conf spark.sql.broadcastTimeout=1200 \
  --conf spark.dynamicAllocation.enabled=true \
  --conf spark.dynamicAllocation.initialExecutors=10 \
  --conf spark.dynamicAllocation.minExecutors=10 \
  --conf spark.dynamicAllocation.maxExecutors=300 \
  --conf spark.shuffle.service.enabled=true \
  --conf spark.executor.memoryOverhead=2048 \
  --conf spark.driver.memoryOverhead=2048 \
  --conf spark.driver.memory=25g \
  --conf spark.executor.memory=10g \
  --conf "spark.executor.extraJavaOptions=-XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+UseG1GC -Djava.io.tmpdir=./tmp" \
  --conf "spark.driver.extraJavaOptions=-XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+UseG1GC" \
  --executor-cores 4 \
  --jars $(echo ../../jars/*.jar | tr ' ' ',') \
  --queue root.datanodo \
  DAICE-spark-1.0-SNAPSHOT-jar-with-dependencies.jar Grupo_fernanda 1704067200000 1706745600000 user/deptorecener/20240223

